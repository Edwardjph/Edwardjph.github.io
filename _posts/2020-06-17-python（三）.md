---
title: Python(三)
tag: python
---

### 八、IO编程

#### 文件读写

##### 读文件

```python
try:
    # errors='ignore'表示遇到编码问题直接忽略
    f = open('text.txt', 'r', encoding='UTF-8', errors='ignore')
    print(f.read())
finally:
    f.close()
```

每次都这么写实在太繁琐，所以，Python引入了`with`语句来自动帮我们调用`close()`方法

```python
#不必调用close()
with open('text.txt', 'r', encoding='UTF-8') as f:
    print(f.read(8))
```

调用`read()`会一次性读取文件的全部内容，为了防止文件过大，内存爆炸，可以反复调用`read(size)`方法，每次最多读取size个字节的内容；

调用`readline()`可以每次读取一行内容，调用`readlines()`一次读取所有内容并按行返回`list`

```python
#读取二进制文件，比如图片、视频等
with open('text.txt', 'rb') as f:
    print(f.read())
```

##### 写文件

```python
with open('text.txt', 'w') as f:
    f.write('Hello, world!')
with open('text.txt', 'a') as f:
    f.write('Hello, world!')
```

以`'w'`模式写入文件时，如果文件已存在，会直接覆盖（相当于删掉后新写入一个文件），可以传入`'a'`以追加（append）模式写入

| 字符  | 含义                                         |
| :---- | :------------------------------------------- |
| `'r'` | 打开以供阅读（默认）                         |
| `'w'` | 打开进行写入，先截断文件                     |
| `'x'` | 打开以进行独占创建，如果文件已经存在，则失败 |
| `'a'` | 打开进行写入，如果存在则追加到文件末尾       |
| `'b'` | 二进制模式                                   |
| `'t'` | 文字模式（默认）                             |
| `'+'` | 开放进行更新（读写）                         |

```python
#a+读写模式，且指针在文件末尾，所以直接读没有内容
with open('text.txt', 'a+', encoding='UTF-8') as f:
    f.write('Hello, world!')
    #读之前将指针重置为文件头
    f.seek(0)
    print(f.read())
```

#### StringIO和BytesIO

##### StringIO

StringIO顾名思义就是在内存中读写str

```python
from io import StringIO

f = StringIO()
#返回写入字符数
f.write('hello ')
f.write('world')
print(f.getvalue())
```

要读取StringIO，可以用一个str初始化StringIO，然后，像读文件一样读取

```python
f = StringIO('Hello!\nHi!\nGoodbye!')
while True:
    s = f.readline()
    if s == '':
        break
    print(s.strip())
```

##### BytesIO

如果要操作二进制数据，就需要使用BytesIO

```python
f = BytesIO(b'\xe4\xb8\xad\xe6\x96\x87')
print(f.read())
```

指针问题

```python
f=StringIO('abc')
f.read() #返回'abc'
f.read() #返回'' 因为使用过一次read之后指针会发生移动
f.getvalue() #返回'abc' 因为getvalue不受指针影响

f=StringIO('')
f.write('abc')
f.read() #返回'' 因为write已经使指针发生了移动
f.getvalue() #返回'abc' 因为getvalue不受指针影响
f.seek(0) #解决方法：用seek将指针归零
f.read() #返回'abc'
f.tell() #返回指针所在位置
```

#### 操作文件和目录

Python内置的`os`模块可以直接调用操作系统提供的接口函数

```python
import os

print(os.name)
#如果是posix，说明系统是Linux、Unix或Mac OS X，如果是nt，就是Windows系统
>>>nt
#获取详细的系统信息，但在Windows上不提供
print(os.uname())
#获取操作系统中定义的环境变量
print(os.environ.get('PATH'))
```

操作文件和目录的函数一部分放在`os`模块中，一部分放在`os.path`模块中

```python
import os

#查看当前目录的绝对路径
print(os.path.abspath('.'))
#在某个目录下创建一个新目录
#首先进行路径拼接
print(os.path.join('.', 'testdir'))
#然后创建目录
os.mkdir(r'.\testdir')
#删除目录
os.rmdir(r'.\testdir')
#把一个路径拆分为两部分，后一部分总是最后级别的目录或文件名
print(os.path.split(r'.\testdir'))
#获得文件的扩展名
print(os.path.splitext(r'.\text.txt'))
#重命名
os.rename('test.txt', 'test.py')
#删除文件
os.remove('test.py')
```

合并、拆分路径的函数并不要求目录和文件要真实存在，它们只对字符串进行操作

os模块不存在复制文件函数，原因是复制文件并非由操作系统提供的系统调用；我们可以使用`shutil`模块提供的`copyfile()`的函数

```python
import shutil

shutil.copyfile(r'.\text.txt', r'.\text2.txt')
```

一句代码列出当前目录下的所有目录

```python
print([x for x in os.listdir('.') if os.path.isdir(x)])
```

一句代码列出所有的`.py`文件

```python
print([x for x in os.listdir('.') if os.path.isfile(x) and os.path.splitext(x)[1] == '.py'])
```

#### 序列化

把变量从内存中变成可存储或传输的过程称之为序列化；

序列化之后，就可以把序列化后的内容写入磁盘，或者通过网络传输到别的机器上；

```python
import pickle

d = dict(name='Bob', age=20, score=88)
#pickle.dumps()方法把任意对象序列化成一个bytes
print(pickle.dumps(d))
#写入文件
with open('dump.txt', 'wb+') as f:
    #直接把对象序列化后写入一个file-like Object
    pickle.dump(d, f)
    f.seek(0)
    #pickle.load()反序列化
    print(pickle.load(f))
```

**pickle只能用于Python，并且可能不同版本的Python彼此都不兼容，因此，只能用Pickle保存那些不重要的数据，不能成功地反序列化也没关系**

#### JSON

如果我们要在不同的编程语言之间传递对象，就必须把对象序列化为标准格式，比如XML，但更好的方法是序列化为JSON，因为JSON表示出来就是一个字符串，可以被所有语言读取，也可以方便地存储到磁盘或者通过网络传输。JSON不仅是标准格式，并且比XML更快，而且可以直接在Web页面中读取，非常方便。

```python
import json

d = dict(name='Bob', age=20, score=88)
json_str = json.dumps(d)
print(json_str)
print(json.loads(json_str))
```

`dumps()`方法返回一个`str`，内容就是标准的JSON。类似的，`dump()`方法可以直接把JSON写入一个`file-like Object`;

用`loads()`或者对应的`load()`方法，前者把JSON的字符串反序列化，后者从`file-like Object`中读取字符串并反序列化;

类的实例无法直接序列化为JSON

```python
class Student(object):
    def __init__(self, name, age, score):
        self.name = name
        self.age = age
        self.score = score

s = Student('Bob', 20, 88)
print(json.dumps(s))
>>>TypeError: Object of type Student is not JSON serializable
#自定义一个转换函数，缺点就是每个类都需要特殊定制
def studentdict(std):
    return {
        'name': std.name,
        'age': std.age,
        'score': std.score
    }
print(json.dumps(s, default=studentdict))
#把任意class的实例变为dict
json_str = json.dumps(s, default=lambda obj: obj.__dict__)
print(json_str)

#反序列化
def dictstudent(d):
    return Student(d['name'], d['age'], d['score'])
print(json.loads(json_str, object_hook=dictstudent))
```

### 九、进程和线程

#### 多进程

##### multiprocessing

```python
from multiprocessing import Process
import os

def run_proc(name):
    print('Run child process %s (%s)...' % (name, os.getpid()))

if __name__ == '__main__':
    print('Parent process %s:' % os.getpid())
    #创建子进程，target：执行函数，args：参数
    p = Process(target=run_proc, args=('test',))
    print('Child process will start.')
    #启动子进程
    p.start()
    #等待子进程结束后再继续往下运行，通常用于进程间的同步
    p.join()
    print('Child process end.')
```

##### Pool

要启动大量的子进程，可以用进程池的方式批量创建子进程

```python
from multiprocessing import Pool
import os, time, random

def long_time_task(name):
    print('Run task %s (%s)...' % (name, os.getpid()))
    start = time.time()
    time.sleep(random.random() * 3)
    end = time.time()
    print('Task %s runs %0.2f seconds' % (name, (end - start)))

if __name__ == '__main__':
    print('Parent process %s:' % os.getpid())
    #创建进程池
    p = Pool(4)
    for i in range(5):
        #添加进程，apply_async：异步非阻塞式（需要join函数来等待子进程运行完毕，否则主进程直接结束），					 apply：阻塞式（一个子进程运行完才运行下一个，不需要join函数）
        p.apply_async(long_time_task, args=(i,))
    print('Waiting for all subprocesses done...')
    #关闭进程池，不能再添加进程
    p.close()
    #等待所有子进程执行完毕
    p.join()
    print('All subprocesses done.')
```

##### 子进程（与系统进行交互）

subprocess是Python 2.4中新增的一个模块，它允许你生成新的进程，连接到它们的 input/output/error 管道，并获取它们的返回（状态）码

subprocess 模块首先推荐使用的是它的 run 方法，更高级的用法可以直接使用 Popen 接口

```python
subprocess.run(args, *, stdin=None, input=None, stdout=None, stderr=None, capture_output=False, shell=False, cwd=None, timeout=None, check=False, encoding=None, errors=None, text=None, env=None, universal_newlines=None)
```

- args：表示要执行的命令。必须是一个字符串，字符串参数列表。
- stdin、stdout 和 stderr：子进程的标准输入、输出和错误。其值可以是 subprocess.PIPE、subprocess.DEVNULL、一个已经存在的文件描述符、已经打开的文件对象或者 None。subprocess.PIPE 表示为子进程创建新的管道。subprocess.DEVNULL 表示使用 os.devnull。默认使用的是 None，表示什么都不做。另外，stderr 可以合并到 stdout 里一起输出。
- timeout：设置命令超时时间。如果命令执行时间超时，子进程将被杀死，并弹出 TimeoutExpired 异常。
- check：如果该参数设置为 True，并且进程退出状态码不是 0，则弹 出 CalledProcessError 异常。
- encoding: 如果指定了该参数，则 stdin、stdout 和 stderr 可以接收字符串数据，并以该编码方式编码。否则只接收 bytes 类型的数据。
- shell：如果该参数为 True，将通过操作系统的 shell 执行指定的命令。

```python
import subprocess

r = subprocess.run(['nslookup', 'www.python.org'])
print(r)
>>>
非权威应答:
服务器:  public1.114dns.com
Address:  114.114.114.114

名称:    dualstack.python.map.fastly.net
Addresses:  2a04:4e42:1a::223
	  151.101.108.223
Aliases:  www.python.org

CompletedProcess(args=['nslookup', 'www.python.org'], returncode=0)
```

**注：此处输出可能会出现中文乱码，需要设置Editor-File Encodings-Global Encoding，改为GBK即可**

Popen 是 subprocess的核心，子进程的创建和管理都靠它处理。

```python
class subprocess.Popen(args, bufsize=-1, executable=None, stdin=None, stdout=None, stderr=None, preexec_fn=None, close_fds=True, shell=False, cwd=None, env=None, universal_newlines=False, startupinfo=None, creationflags=0,restore_signals=True, start_new_session=False, pass_fds=(),*, encoding=None, errors=None)
```

- args：shell命令，可以是字符串或者序列类型（如：list，元组）
- bufsize：缓冲区大小。当创建标准流的管道对象时使用，默认-1。
  0：不使用缓冲区
  1：表示行缓冲，仅当universal_newlines=True时可用，也就是文本模式
  正数：表示缓冲区大小
  负数：表示使用系统默认的缓冲区大小。
- stdin, stdout, stderr：分别表示程序的标准输入、输出、错误句柄
- preexec_fn：只在 Unix 平台下有效，用于指定一个可执行对象（callable object），它将在子进程运行之前被调用
- shell：如果该参数为 True，将通过操作系统的 shell 执行指定的命令。
- cwd：用于设置子进程的当前目录。
- env：用于指定子进程的环境变量。如果 env = None，子进程的环境变量将从父进程中继承。

**Popen 对象方法**

- poll(): 检查进程是否终止，如果终止返回 returncode，否则返回 None。
- wait(timeout): 等待子进程终止。
- communicate(input,timeout): 和子进程交互，发送和读取数据。
- send_signal(singnal): 发送信号到子进程 。
- terminate(): 停止子进程,也就是发送SIGTERM信号到子进程。
- kill(): 杀死子进程。发送 SIGKILL 信号到子进程。

```python
p = subprocess.Popen('java -version', stdout=subprocess.PIPE, stderr=subprocess.PIPE, encoding="utf-8")
print(p.communicate()[1])
>>>
openjdk version "11.0.2" 2019-01-15
OpenJDK Runtime Environment (build 11.0.2+9-b159.64)
OpenJDK 64-Bit Server VM (build 11.0.2+9-b159.64, mixed mode, sharing)
```

如果子进程还需要输入

```python
p = subprocess.Popen('nslookup', stdin=subprocess.PIPE, stdout=subprocess.PIPE, stderr=subprocess.PIPE)
p.communicate(b'set q=mx\npython.org\nexit\n')
print(p.communicate()[0].decode('GBK'))
```

##### 进程间的通信

Python的`multiprocessing`模块包装了底层的机制，提供了`Queue`、`Pipes`等多种方式来交换数据

```python
from multiprocessing import Process, Queue
import os, time, random

def write(q):
    print('Process to write: %s' % os.getpid())
    for value in ['A', 'B', 'C']:
        print('Put %s to queue...' % value)
        q.put(value)
        time.sleep(random.random())

def read(q):
    print('Process to read: %s' % os.getpid())
    while True:
        value = q.get(True)
        print('Get %s from queue.' % value)

if __name__ == '__main__':
    #父进程创建Queue，并传递给各个子进程
    q = Queue()
    pw = Process(target=write, args=(q,))
    pr = Process(target=read, args=(q,))
    pw.start()
    pr.start()
    pw.join()
    #pr进程里是死循环，无法等待其结束，只能强制终止
    pr.terminate()
```

#### 多线程

```python
import time, threading

def loop():
    print('thread %s is running...' % threading.current_thread().name)
    n = 0
    while n < 5:
        n = n + 1
        print('thread %s >>> %s' % (threading.current_thread().name, n))
        time.sleep(1)
    print('threa %s ended' % threading.current_thread().name)
#threading.current_thread().name当前线程的名称
print('thread %s is running...' % threading.current_thread().name)
#创建一个新的线程
t = threading.Thread(target=loop, name='LoopThread')
#启动
t.start()
#等待
t.join()
print('thread %s ended' % threading.current_thread().name)
```

##### lock

多进程中，同一个变量，各自有一份拷贝存在于每个进程中，互不影响，而多线程中，所有变量都由所有线程共享，所以，任何一个变量都可以被任何一个线程修改，有可能出现混乱

这时我们就需要使用锁

```python
balance = 0
#定义锁
lock = threading.Lock()

def change_it(n):
    #global定义全局变量
    global balance
    #先加后减，结果应该为0
    balance = balance + n
    balance = balance - n

def run_thread(n):
    for i in range(1000000):
        #获取锁
        lock.acquire()
        try:
            change_it(n)
        finally:
            #释放锁
            lock.release()

t1 = threading.Thread(target=run_thread, args=(5,))
t2 = threading.Thread(target=run_thread, args=(8,))
t1.start()
t2.start()
t1.join()
t2.join()
print(balance)
```

**关于Python多线程与多核CPU**

Python解释器执行代码时，有一个GIL锁：Global Interpreter Lock，任何Python线程执行前，必须先获得GIL锁，然后，每执行100条字节码，解释器就自动释放GIL锁，让别的线程有机会执行。这个GIL全局锁实际上把所有线程的执行代码都给上了锁，所以，多线程在Python中只能交替执行，即使100个线程跑在100核CPU上，也只能用到1个核；

在Python中，可以使用多线程，但不要指望能有效利用多核；

Python虽然不能利用多线程实现多核任务，但可以通过多进程实现多核任务。多个Python进程有各自独立的GIL锁，互不影响。

#### ThreadLocal

使用全局变量时必须加锁，且有时因为每个线程处理不同的对象，不能共享，不能使用全局变量；

但是局部变量又需要随着函数一直传递下去，略显麻烦；

可以用一个全局`dict`存放所有的对象，然后以`thread`自身作为`key`获得线程对应的对象；

```python
global_dict = {}

def std_thread(name):
    std = Student(name)
    #以`thread`自身作为`key`存入对应的std对象
    global_dict[threading.current_thread()] = std
    do_task_1()
    do_task_2()
    
def do_task_1():
    #不传入std，而是根据当前线程去查找
    std = global_dict[threading.current_thread()]
    pass

def do_task_2():
    std = global_dict[threading.current_thread()]
    pass
```

python为我们提供了ThreadLocal完成上面的操作

```python
#创建全局ThreadLocal对象
local_school = threading.local()

def process_student():
    std = local_school.student
    print('Hello, %s (in %s)' % (std, threading.current_thread().name))

def process_thread(name):
    local_school.student = name
    process_student()

t1 = threading.Thread(target= process_thread, args=('Alice',), name='Thread-A')
t2 = threading.Thread(target= process_thread, args=('Bob',), name='Thread-B')
t1.start()
t2.start()
t1.join()
t2.join()
```